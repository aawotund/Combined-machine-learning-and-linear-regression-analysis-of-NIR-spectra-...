{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LeNet 2DCNN.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "V_T1ecOYwLy2"
      },
      "source": [
        "# Library imports\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "from scipy.signal import savgol_filter\n",
        "from sklearn.decomposition import PCA as sk_pca\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn import svm\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.pipeline import Pipeline\n",
        "import keras\n",
        "from numpy import loadtxt\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jm4StKXwCZt6"
      },
      "source": [
        "\n",
        "def snv(input_data):\n",
        "  \n",
        "    # Define a new array and populate it with the corrected data  \n",
        "    output_data = np.zeros_like(input_data)\n",
        "    for i in range(input_data.shape[0]):\n",
        " \n",
        "        # Apply correction\n",
        "        output_data[i,:] = (input_data[i,:] - np.mean(input_data[i,:])) / np.std(input_data[i,:])\n",
        "        #print(output_data)\n",
        "    return output_data"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "86yCmuJbxGrJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dd56536f-3151-48f8-de68-09d683fb2a33"
      },
      "source": [
        "# load the dataset\n",
        "data = pd.read_csv('/content/Acetaminophen_mixture_CNN_Binary.csv', index_col=0)\n",
        "data = pd.DataFrame(data)\n",
        "df = pd.DataFrame()\n",
        "data.drop(['label_name'], axis=1, inplace=True)\n",
        "data.rename(columns={'Unnamed: 0': 'id'},inplace=True)\n",
        "y = data['label']\n",
        "X = data.drop(['label'],axis=1)\n",
        "X = X.values[:,0:]\n",
        "X = snv(X)\n",
        "X = pd.DataFrame(X)\n",
        "print((X.shape))\n",
        "#X = X.values.reshape(900,32,32)\n",
        "for i in range(227,1024,1):\n",
        "  X.insert(loc=i, column=i, value=0)\n",
        "print((X.shape))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(900, 227)\n",
            "(900, 1024)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-q4neHHZTB1t",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "outputId": "4336aafd-56c5-48da-b607-ae7f649148bb"
      },
      "source": [
        "plot = X.values.reshape(900,32,32)\n",
        "sample_plot =plot[0]\n",
        "print(sample_plot.shape)\n",
        "plt.imshow(sample_plot,cmap='gray')\n",
        "plt.show()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(32, 32)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD5CAYAAADhukOtAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAN5klEQVR4nO3db6gddX7H8c8nyYl/Nspqk4YQQ921sqsPulEuwbKybHebNc2TKCxFHyx5ELihrKCwfRC20FroA7dUpY8ssYaNxWptVQxF2k2DIAsl69XGmD81cSXLJsTcLnbVirg393774EzgJJyZe+6cmTnR7/sFlzNnZn4z30zO5/yZ3zm/cUQIwOffskkXAKAbhB1IgrADSRB2IAnCDiRB2IEkVozT2PYWSX8rabmkv4+IhxdZP2wPXfZZ7gIs+ze11Q4os7CwoIgY+sBy3ZDZXi7phKTNkk5Lek3SfRFxrKzNsmXLotfrDV12/vz5qn0NnT8/P7/kNlL1E8vy5cuXvM2qNsuWlb95qqqxqt3CwsKSt/lZeGK5XGqsenzUrbGNbQ7z8ccfa35+fugGx3kbv0nSOxHxbkT8RtKzkraNsT0ALRon7Osl/XLg/uliHoDL0Fif2Udhe1rSdNv7AVBtnLCfkbRh4P4NxbyLRMRuSbul/mf2MfYHYAzjvI1/TdLNtr9ke6WkeyXta6YsAE2r/coeEedt3y/p39XvetsTEUer2tjWypUrhy674oor6tRQua86mu4CrNpe1Vn1qmVV6rYrU/c4lvUm1OntWKxdlbJ2Vb0dVcvKHr9S9f91ncdBVQ9VWZtPPvmktM1Yn9kj4mVJL4+zDQDd4Bt0QBKEHUiCsANJEHYgCcIOJNH6N+gGLVu2TFdffXWtdk3XUaZOd17VD3KqtlfVrmpZlbL9VXXJVdVY91iVLavbFVnnh1JV26z7Q6m6P16q0uQvQauOIa/sQBKEHUiCsANJEHYgCcIOJNHp2fiI0KefftrY9toYxqhqm3X2V7fGuj/8KDuDW3d7dZX9u+ue3a/7A5qy/dUdLqzpHwZVLatTR1W+eGUHkiDsQBKEHUiCsANJEHYgCcIOJNFp19uKFSu0evXqocvqjD9W90cJTXet1O3Wulzqb0OXP15qul3d8enqbrPOOHllbWZnZ8trKF0C4HOFsANJEHYgCcIOJEHYgSQIO5DEWF1vtk9J+kjSvKTzETFVtf6VV16pW265ZXghK8pLKetmqLoUT9X26i6r0wVY99daTY911kY3X52uoarjW/X/WWdfVe26vjxY1b+7bJt1ugCPHi2/AlsT/ex/EBG/amA7AFrE23ggiXHDHpJ+Yvt129NNFASgHeO+jb8zIs7Y/m1J+23/d0S8OrhC8SQwLUlXXXXVmLsDUNdYr+wRcaa4nZX0oqRNQ9bZHRFTETFVdQIGQLtqh932F2xfc2Fa0nckHWmqMADNGudt/FpJLxZdGCsk/WNE/FtVg2uvvVZ33XXX8EIquiaa/iVXr9crXVZ1+ZyydyZ1u96qulaqLpNV1f1T1q5uF1rVZZeqBjcsO8Z1L7tU9X9WdazKPjpWfaSsqqOqXdVjZ9WqVUveZtVjp6zNU089Vdqmdtgj4l1JX6vbHkC36HoDkiDsQBKEHUiCsANJEHYgiU4HnFyzZo127tw5dNkHH3xQ2q5s2Y4dOxqpC/i8ePvtt0uX8coOJEHYgSQIO5AEYQeSIOxAEp2ejT9x4oQ2b97c5S4BFHhlB5Ig7EAShB1IgrADSRB2IAnCDiRB2IEkCDuQBGEHkiDsQBKEHUiCsANJEHYgiUXDbnuP7VnbRwbmXW97v+2Txe117ZYJYFyjvLL/WNKWS+btknQgIm6WdKC4D+AytmjYi+utv3/J7G2S9hbTeyXd3XBdABpW9zP72og4W0y/p/4VXQFcxsY+QRf969uWXuPW9rTtGdszc3Nz4+4OQE11w37O9jpJKm5ny1aMiN0RMRURU1XX2AbQrrph3ydpezG9XdJLzZQDoC2jdL09I+k/JX3F9mnbOyQ9LGmz7ZOS/rC4D+AytujoshFxX8mibzdcC4AW8Q06IAnCDiRB2IEkCDuQBGEHkiDsQBKEHUiCsANJEHYgCcIOJEHYgSQIO5AEYQeSIOxAEoQdSIKwA0kQdiAJwg4kQdiBJAg7kARhB5Ig7EAShB1IgrADSRB2IIlRLv+0x/as7SMD8x6yfcb2oeJva7tlAhjXKK/sP5a0Zcj8xyJiY/H3crNlAWjaomGPiFclvd9BLQBaNM5n9vttHy7e5l/XWEUAWlE37I9LuknSRklnJT1StqLtadsztmfm5uZq7g7AuGqFPSLORcR8RCxIekLSpop1d0fEVERM9Xq9unUCGFOtsNteN3D3HklHytYFcHlYsdgKtp+R9E1Jq22flvQXkr5pe6OkkHRK0s4WawTQgEXDHhH3DZn9ZAu1AGgR36ADkiDsQBKEHUiCsANJEHYgCcIOJEHYgSQIO5AEYQeSIOxAEoQdSIKwA0kQdiAJwg4kQdiBJAg7kARhB5Ig7EAShB1IgrADSRB2IAnCDiRB2IEkCDuQBGEHklg07LY32H7F9jHbR20/UMy/3vZ+2yeLWy7bDFzGRnllPy/pBxFxq6Q7JH3f9q2Sdkk6EBE3SzpQ3AdwmVo07BFxNiLeKKY/knRc0npJ2yTtLVbbK+nutooEML4lfWa3faOk2yQdlLQ2Is4Wi96TtLbRygA0auSw214l6XlJD0bEh4PLIiLUv3zzsHbTtmdsz8zNzY1VLID6Rgq77Z76QX86Il4oZp+zva5Yvk7S7LC2EbE7IqYiYqrX6zVRM4AaRjkbb/Wvx348Ih4dWLRP0vZierukl5ovD0BTVoywztclfU/SW7YPFfN+KOlhSc/Z3iHpF5L+uJ0SATRh0bBHxE8luWTxt5stB0Bb+AYdkARhB5Ig7EAShB1IgrADSRB2IAnCDiRB2IEkCDuQBGEHkiDsQBKEHUiCsANJEHYgCcIOJEHYgSQIO5AEYQeSIOxAEoQdSIKwA0kQdiAJwg4kQdiBJAg7kMQo13rbYPsV28dsH7X9QDH/IdtnbB8q/ra2Xy6Auka51tt5ST+IiDdsXyPpddv7i2WPRcTftFcegKaMcq23s5LOFtMf2T4uaX3bhQFo1pI+s9u+UdJtkg4Ws+63fdj2HtvXNVwbgAaNHHbbqyQ9L+nBiPhQ0uOSbpK0Uf1X/kdK2k3bnrE9Mzc310DJAOoYKey2e+oH/emIeEGSIuJcRMxHxIKkJyRtGtY2InZHxFRETPV6vabqBrBEo5yNt6QnJR2PiEcH5q8bWO0eSUeaLw9AU0Y5G/91Sd+T9JbtQ8W8H0q6z/ZGSSHplKSdrVQIoBGjnI3/qSQPWfRy8+UAaAvfoAOSIOxAEoQdSIKwA0kQdiAJwg4kQdiBJAg7kARhB5Ig7EAShB1IgrADSRB2IAnCDiRB2IEkCDuQBGEHkiDsQBKEHUiCsANJEHYgCcIOJEHYgSQIO5AEYQeSGOVab1fa/pntN20ftf2Xxfwv2T5o+x3b/2R7ZfvlAqhrlFf2TyV9KyK+pv7lmbfYvkPSjyQ9FhG/K+l/Je1or0wA41o07NH3f8XdXvEXkr4l6V+K+Xsl3d1KhQAaMer12ZcXV3CdlbRf0s8l/ToizhernJa0vp0SATRhpLBHxHxEbJR0g6RNkr466g5sT9uesT0zNzdXs0wA41rS2fiI+LWkVyT9vqQv2r5wyecbJJ0pabM7IqYiYqrX641VLID6Rjkbv8b2F4vpqyRtlnRc/dB/t1htu6SX2ioSwPhWLL6K1knaa3u5+k8Oz0XEv9o+JulZ238l6b8kPdlinQDGtGjYI+KwpNuGzH9X/c/vAD4D+AYdkARhB5Ig7EAShB1IgrADSTgiutuZ/T+SflHcXS3pV53tvBx1XIw6LvZZq+N3ImLNsAWdhv2iHdszETE1kZ1TB3UkrIO38UAShB1IYpJh3z3BfQ+ijotRx8U+N3VM7DM7gG7xNh5IYiJht73F9tvFYJW7JlFDUccp22/ZPmR7psP97rE9a/vIwLzrbe+3fbK4vW5CdTxk+0xxTA7Z3tpBHRtsv2L7WDGo6QPF/E6PSUUdnR6T1gZ5jYhO/yQtV39Yqy9LWinpTUm3dl1HUcspSasnsN9vSLpd0pGBeX8taVcxvUvSjyZUx0OS/rTj47FO0u3F9DWSTki6tetjUlFHp8dEkiWtKqZ7kg5KukPSc5LuLeb/naQ/Wcp2J/HKvknSOxHxbkT8RtKzkrZNoI6JiYhXJb1/yext6g/cKXU0gGdJHZ2LiLMR8UYx/ZH6g6OsV8fHpKKOTkVf44O8TiLs6yX9cuD+JAerDEk/sf267ekJ1XDB2og4W0y/J2ntBGu53/bh4m1+6x8nBtm+Uf3xEw5qgsfkkjqkjo9JG4O8Zj9Bd2dE3C7pjyR93/Y3Jl2Q1H9mV/+JaBIel3ST+tcIOCvpka52bHuVpOclPRgRHw4u6/KYDKmj82MSYwzyWmYSYT8jacPA/dLBKtsWEWeK21lJL2qyI++cs71Okorb2UkUERHnigfagqQn1NExsd1TP2BPR8QLxezOj8mwOiZ1TIp9L3mQ1zKTCPtrkm4uziyulHSvpH1dF2H7C7avuTAt6TuSjlS3atU+9QfulCY4gOeFcBXuUQfHxLbVH8PweEQ8OrCo02NSVkfXx6S1QV67OsN4ydnGreqf6fy5pD+bUA1fVr8n4E1JR7usQ9Iz6r8dnFP/s9cOSb8l6YCkk5L+Q9L1E6rjHyS9Jemw+mFb10Edd6r/Fv2wpEPF39auj0lFHZ0eE0m/p/4grofVf2L584HH7M8kvSPpnyVdsZTt8g06IInsJ+iANAg7kARhB5Ig7EAShB1IgrADSRB2IAnCDiTx/2eRpFnQxkn6AAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Du5vfUEEy5sZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0fd31b75-570c-4e6b-bba0-45d88116a70b"
      },
      "source": [
        "# fit the keras model on the dataset\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=2)\n",
        "\n",
        "X_train = X_train.values.reshape(X_train.shape[0],32,32,1).astype('float32')\n",
        "X_test= X_test.values.reshape(X_test.shape[0],32,32,1).astype('float32')\n",
        "print(X_train.shape)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(720, 32, 32, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n4mpCbSg30BV"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "early_stopping = EarlyStopping(\n",
        "    #monitor='val_accuracy', \n",
        "    monitor='loss',\n",
        "    patience=0, \n",
        "    #min_delta=0.001, \n",
        "    mode='max'\n",
        ")\n",
        "n_timesteps = X_train.shape[1] \n",
        "n_features  = X_train.shape[2]  \n",
        "#model = keras.Sequential(name=\"model_conv2D\")\n",
        "#model.add(keras.layers.Input(shape=(n_timesteps,n_features,1)))\n",
        "model = keras.Sequential()\n",
        "\n",
        "model.add(keras.layers.Conv2D(filters=6, kernel_size=(3, 3), activation='relu', input_shape=(32,32,1)))\n",
        "model.add(keras.layers.AveragePooling2D())\n",
        "\n",
        "model.add(keras.layers.Conv2D(filters=16, kernel_size=(3, 3), activation='relu'))\n",
        "model.add(keras.layers.AveragePooling2D())\n",
        "\n",
        "model.add(keras.layers.Flatten())\n",
        "\n",
        "model.add(keras.layers.Dense(units=256, activation='relu'))\n",
        "\n",
        "model.add(keras.layers.Dense(units=84, activation='relu'))\n",
        "\n",
        "model.add(keras.layers.Dense(units=1, activation = 'relu'))\n",
        "\n",
        "model.compile(loss='mse', optimizer='adam', metrics='mse')"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nP3dVBsBK3s_",
        "outputId": "1b5b38dc-9d21-44ea-bd13-3f9b1f0ae5d5"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 30, 30, 6)         60        \n",
            "_________________________________________________________________\n",
            "average_pooling2d (AveragePo (None, 15, 15, 6)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 13, 13, 16)        880       \n",
            "_________________________________________________________________\n",
            "average_pooling2d_1 (Average (None, 6, 6, 16)          0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 576)               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 256)               147712    \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 84)                21588     \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 1)                 85        \n",
            "=================================================================\n",
            "Total params: 170,325\n",
            "Trainable params: 170,325\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4NKR8b4SNPbO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cec4c4a0-996e-4923-e618-2cee9c9b5f35"
      },
      "source": [
        "history = model.fit(X_train, y_train, epochs=20,verbose=1)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "23/23 [==============================] - 1s 18ms/step - loss: 0.1705 - mse: 0.1705\n",
            "Epoch 2/20\n",
            "23/23 [==============================] - 0s 16ms/step - loss: 0.1287 - mse: 0.1287\n",
            "Epoch 3/20\n",
            "23/23 [==============================] - 0s 17ms/step - loss: 0.0596 - mse: 0.0596\n",
            "Epoch 4/20\n",
            "23/23 [==============================] - 0s 17ms/step - loss: 0.0127 - mse: 0.0127\n",
            "Epoch 5/20\n",
            "23/23 [==============================] - 0s 17ms/step - loss: 0.0080 - mse: 0.0080\n",
            "Epoch 6/20\n",
            "23/23 [==============================] - 0s 17ms/step - loss: 0.0069 - mse: 0.0069\n",
            "Epoch 7/20\n",
            "23/23 [==============================] - 0s 17ms/step - loss: 0.0071 - mse: 0.0071\n",
            "Epoch 8/20\n",
            "23/23 [==============================] - 0s 17ms/step - loss: 0.0061 - mse: 0.0061\n",
            "Epoch 9/20\n",
            "23/23 [==============================] - 0s 17ms/step - loss: 0.0053 - mse: 0.0053\n",
            "Epoch 10/20\n",
            "23/23 [==============================] - 0s 18ms/step - loss: 0.0051 - mse: 0.0051\n",
            "Epoch 11/20\n",
            "23/23 [==============================] - 0s 17ms/step - loss: 0.0050 - mse: 0.0050\n",
            "Epoch 12/20\n",
            "23/23 [==============================] - 0s 17ms/step - loss: 0.0051 - mse: 0.0051\n",
            "Epoch 13/20\n",
            "23/23 [==============================] - 0s 18ms/step - loss: 0.0050 - mse: 0.0050\n",
            "Epoch 14/20\n",
            "23/23 [==============================] - 0s 17ms/step - loss: 0.0044 - mse: 0.0044\n",
            "Epoch 15/20\n",
            "23/23 [==============================] - 0s 17ms/step - loss: 0.0036 - mse: 0.0036\n",
            "Epoch 16/20\n",
            "23/23 [==============================] - 0s 17ms/step - loss: 0.0037 - mse: 0.0037\n",
            "Epoch 17/20\n",
            "23/23 [==============================] - 0s 16ms/step - loss: 0.0035 - mse: 0.0035\n",
            "Epoch 18/20\n",
            "23/23 [==============================] - 0s 18ms/step - loss: 0.0041 - mse: 0.0041\n",
            "Epoch 19/20\n",
            "23/23 [==============================] - 0s 17ms/step - loss: 0.0038 - mse: 0.0038\n",
            "Epoch 20/20\n",
            "23/23 [==============================] - 0s 17ms/step - loss: 0.0029 - mse: 0.0029\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OR28le6cNvaO",
        "outputId": "199e445d-dc94-4d8a-886e-235d2d8379bd"
      },
      "source": [
        "mse = model.evaluate(X_test, y_test)\n",
        "print('Accuracy: %.2f',mse)\n",
        "#print(history.history['mse'])\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0028 - mse: 0.0028\n",
            "Accuracy: %.2f [0.0028382556047290564, 0.0028382556047290564]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vuAtGi2Aon-L",
        "outputId": "3b5d86b6-adb8-473f-d7ef-6fe7e0b9d076"
      },
      "source": [
        "myst = pd.read_csv('/content/Mystery_testing_data.csv', index_col=0)\n",
        "myst = pd.DataFrame(myst)\n",
        "predictions =[]\n",
        "myst_predictions = pd.DataFrame(myst[\"label_name\"])\n",
        "myst.drop(['label_name'], axis=1, inplace=True)\n",
        "# Applying SNV to myst data\n",
        "myst = myst.values[:,0:]\n",
        "myst = snv(myst)\n",
        "myst = pd.DataFrame(myst)\n",
        "for i in range(227,1024,1):\n",
        "  myst.insert(loc=i, column=i, value=0)\n",
        "print((X.shape))\n",
        "myst= myst.values.reshape(myst.shape[0],32,32,1).astype('float32')\n",
        "preds = model.predict(myst)\n",
        "print(preds)\n",
        "se = pd.Series(preds.tolist())\n",
        "#print(se.values)\n",
        "#myst_predictions.insert(loc=0, column='predictions', value=[sum(se.values)/len(se.values)])\n",
        "#myst_predictions.insert(loc=1, column='predictions', value=se.values)\n",
        "for i in range(0, 100):\n",
        "  #myst_predictions.insert(loc=1, column='molar_mass', value=se[i].values)\n",
        "  predictions.append((sum(se[i])/len(se[i])))\n",
        "#print(myst_predictions)\n",
        "myst_predictions.insert(loc=1, column='predictions', value=predictions)\n",
        "\n",
        "#myst['class_label'] = [1 if x > 0.5 else 0 for x in myst['predictions']]\n",
        "#myst_predictions.insert(loc=2, column='Class Name', value=se.values)\n",
        "\n",
        "myst_predictions.to_csv('/content/Mystery_Prediction_2DCNN_data_binary.csv')"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(900, 1024)\n",
            "[[0.9511771 ]\n",
            " [0.9406878 ]\n",
            " [0.935905  ]\n",
            " [0.94680333]\n",
            " [0.94925463]\n",
            " [0.9429027 ]\n",
            " [0.93497944]\n",
            " [0.9429257 ]\n",
            " [0.9433913 ]\n",
            " [0.94524586]\n",
            " [0.9933778 ]\n",
            " [1.0074229 ]\n",
            " [1.0140865 ]\n",
            " [0.9985409 ]\n",
            " [1.0144467 ]\n",
            " [1.0109715 ]\n",
            " [1.0007465 ]\n",
            " [0.9920665 ]\n",
            " [1.0037289 ]\n",
            " [1.009953  ]\n",
            " [0.4480321 ]\n",
            " [0.46672615]\n",
            " [0.44449475]\n",
            " [0.45786336]\n",
            " [0.44009173]\n",
            " [0.47045094]\n",
            " [0.44077787]\n",
            " [0.44242617]\n",
            " [0.37225136]\n",
            " [0.46521375]\n",
            " [0.87158346]\n",
            " [0.8672373 ]\n",
            " [0.86547196]\n",
            " [0.87319946]\n",
            " [0.89684725]\n",
            " [0.8686224 ]\n",
            " [0.8668562 ]\n",
            " [0.86537945]\n",
            " [0.8538511 ]\n",
            " [0.88080955]\n",
            " [0.6076791 ]\n",
            " [0.47913572]\n",
            " [0.41770142]\n",
            " [0.50455976]\n",
            " [0.41533968]\n",
            " [0.53512716]\n",
            " [0.5663179 ]\n",
            " [0.479158  ]\n",
            " [0.49949157]\n",
            " [0.48742995]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.        ]\n",
            " [0.10169134]\n",
            " [0.06557798]\n",
            " [0.09991204]\n",
            " [0.12055127]\n",
            " [0.12512739]\n",
            " [0.08037375]\n",
            " [0.07035696]\n",
            " [0.10515112]\n",
            " [0.08813499]\n",
            " [0.16965999]\n",
            " [0.89538884]\n",
            " [0.89329636]\n",
            " [0.90087676]\n",
            " [0.8931005 ]\n",
            " [0.9013816 ]\n",
            " [0.90079296]\n",
            " [0.89658153]\n",
            " [0.89979684]\n",
            " [0.9046881 ]\n",
            " [0.8940995 ]\n",
            " [0.92850196]\n",
            " [0.8643688 ]\n",
            " [0.8793087 ]\n",
            " [0.87303007]\n",
            " [0.9185257 ]\n",
            " [0.87417805]\n",
            " [0.9077133 ]\n",
            " [0.8958992 ]\n",
            " [0.923646  ]\n",
            " [0.9337299 ]\n",
            " [0.08407231]\n",
            " [0.09529664]\n",
            " [0.08756527]\n",
            " [0.04116146]\n",
            " [0.14129353]\n",
            " [0.15310934]\n",
            " [0.0422425 ]\n",
            " [0.08074   ]\n",
            " [0.10483649]\n",
            " [0.05241092]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gNoV7SmVzR15",
        "outputId": "3c515b0d-6db6-4a35-d2f5-2e03965be3a2"
      },
      "source": [
        "#Predicting Ternary Samples Data\n",
        "data = pd.read_csv('/content/ternary_samples.csv', index_col=0)\n",
        "data = pd.DataFrame(data)\n",
        "ternary_predictions = pd.DataFrame()\n",
        "\n",
        "ternary_predictions[\"label_name\"] =data[\"label_name\"]\n",
        "ternary_predictions['Actual'] = data['label']\n",
        "\n",
        "data.drop(['label_name'], axis=1, inplace=True)\n",
        "data.rename(columns={'Unnamed: 0': 'id'},inplace=True)\n",
        "\n",
        "y = data['label']\n",
        "X = data.drop(['label'],axis=1)\n",
        "X = X.values[:,0:]\n",
        "X = snv(X)\n",
        "X = pd.DataFrame(X)\n",
        "\n",
        "for i in range(227,1024,1):\n",
        "  X.insert(loc=i, column=i, value=0)\n",
        "\n",
        "\n",
        "ternary= X.values.reshape(X.shape[0],32,32,1).astype('float32')\n",
        "preds = model.predict(ternary)\n",
        "print(preds)\n",
        "se = pd.Series(preds.tolist())\n",
        "ternary_predictions.insert(loc=0, column='predictions', value=se.values)\n",
        "#Saving results\n",
        "ternary_predictions.to_csv('/content/Ternary_Prediction_2DCNN.csv')"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.35595468]\n",
            " [0.45359257]\n",
            " [0.2991018 ]\n",
            " [0.34084255]\n",
            " [0.27578017]\n",
            " [0.22594401]\n",
            " [0.26117185]\n",
            " [0.35836825]\n",
            " [0.31483218]\n",
            " [0.23091239]\n",
            " [0.3598692 ]\n",
            " [0.34147355]\n",
            " [0.40077883]\n",
            " [0.2303319 ]\n",
            " [0.35306588]\n",
            " [0.4110031 ]\n",
            " [0.34197223]\n",
            " [0.3452341 ]\n",
            " [0.33825058]\n",
            " [0.42582604]\n",
            " [0.33403394]\n",
            " [0.26280707]\n",
            " [0.3278751 ]\n",
            " [0.3838348 ]\n",
            " [0.36603695]\n",
            " [0.2832307 ]\n",
            " [0.2943126 ]\n",
            " [0.25592685]\n",
            " [0.18405074]\n",
            " [0.43165353]\n",
            " [0.26019445]\n",
            " [0.3637209 ]\n",
            " [0.3227596 ]\n",
            " [0.4012603 ]\n",
            " [0.38789532]\n",
            " [0.29211777]\n",
            " [0.35496622]\n",
            " [0.3087359 ]\n",
            " [0.25255027]\n",
            " [0.3437399 ]\n",
            " [0.3477753 ]\n",
            " [0.414182  ]\n",
            " [0.3822817 ]\n",
            " [0.24343136]\n",
            " [0.24613693]\n",
            " [0.4161015 ]\n",
            " [0.3151657 ]\n",
            " [0.3883385 ]\n",
            " [0.30791834]\n",
            " [0.25470966]\n",
            " [0.35799092]\n",
            " [0.3832192 ]\n",
            " [0.33371505]\n",
            " [0.38750702]\n",
            " [0.313763  ]\n",
            " [0.30778208]\n",
            " [0.39725634]\n",
            " [0.27454203]\n",
            " [0.32016313]\n",
            " [0.4618866 ]\n",
            " [0.37041807]\n",
            " [0.28813815]\n",
            " [0.36043534]\n",
            " [0.40985635]\n",
            " [0.35571375]\n",
            " [0.41107494]\n",
            " [0.25556463]\n",
            " [0.253279  ]\n",
            " [0.30610833]\n",
            " [0.2351217 ]\n",
            " [0.3723998 ]\n",
            " [0.44947854]\n",
            " [0.3371272 ]\n",
            " [0.29111257]\n",
            " [0.41727483]\n",
            " [0.288979  ]\n",
            " [0.29105195]\n",
            " [0.34026304]\n",
            " [0.23276262]\n",
            " [0.24505799]\n",
            " [0.40513632]\n",
            " [0.35946494]\n",
            " [0.30636415]\n",
            " [0.30442297]\n",
            " [0.3911055 ]\n",
            " [0.3312139 ]\n",
            " [0.3661165 ]\n",
            " [0.3789678 ]\n",
            " [0.32642472]\n",
            " [0.31063372]\n",
            " [0.3540116 ]\n",
            " [0.38924092]\n",
            " [0.27196243]\n",
            " [0.33638054]\n",
            " [0.38788703]\n",
            " [0.29895198]\n",
            " [0.3016351 ]\n",
            " [0.2823878 ]\n",
            " [0.43149492]\n",
            " [0.3038154 ]\n",
            " [0.14835541]\n",
            " [0.00217263]\n",
            " [0.16521324]\n",
            " [0.08122617]\n",
            " [0.15267226]\n",
            " [0.1802015 ]\n",
            " [0.15383343]\n",
            " [0.14121619]\n",
            " [0.16600546]\n",
            " [0.14134772]\n",
            " [0.12857133]\n",
            " [0.17114033]\n",
            " [0.18860103]\n",
            " [0.08263732]\n",
            " [0.02285294]\n",
            " [0.21354459]\n",
            " [0.11407841]\n",
            " [0.09580454]\n",
            " [0.12477006]\n",
            " [0.11388096]\n",
            " [0.11782442]\n",
            " [0.20199941]\n",
            " [0.17693128]\n",
            " [0.23133023]\n",
            " [0.11355461]\n",
            " [0.00471427]\n",
            " [0.17967749]\n",
            " [0.04983737]\n",
            " [0.15439573]\n",
            " [0.22522683]\n",
            " [0.10184807]\n",
            " [0.08645238]\n",
            " [0.1345921 ]\n",
            " [0.        ]\n",
            " [0.14116192]\n",
            " [0.11939625]\n",
            " [0.09341864]\n",
            " [0.07137586]\n",
            " [0.23069564]\n",
            " [0.11177337]\n",
            " [0.06837173]\n",
            " [0.17924778]\n",
            " [0.14253613]\n",
            " [0.16324726]\n",
            " [0.09541982]\n",
            " [0.14956532]\n",
            " [0.13741067]\n",
            " [0.16323096]\n",
            " [0.06806435]\n",
            " [0.04037334]\n",
            " [0.12522966]\n",
            " [0.1261801 ]\n",
            " [0.11971162]\n",
            " [0.07291544]\n",
            " [0.02254698]\n",
            " [0.09681626]\n",
            " [0.09757414]\n",
            " [0.12781829]\n",
            " [0.08568788]\n",
            " [0.13036782]\n",
            " [0.12449157]\n",
            " [0.01877111]\n",
            " [0.06830622]\n",
            " [0.12294038]\n",
            " [0.03706428]\n",
            " [0.14011404]\n",
            " [0.1455173 ]\n",
            " [0.0630172 ]\n",
            " [0.10919285]\n",
            " [0.10864151]\n",
            " [0.20910704]\n",
            " [0.09542141]\n",
            " [0.18019718]\n",
            " [0.14449573]\n",
            " [0.11635503]\n",
            " [0.00660955]\n",
            " [0.17717616]\n",
            " [0.17299819]\n",
            " [0.08463517]\n",
            " [0.12298344]\n",
            " [0.01517968]\n",
            " [0.1831082 ]\n",
            " [0.21036258]\n",
            " [0.15000814]\n",
            " [0.10678436]\n",
            " [0.16828294]\n",
            " [0.0764046 ]\n",
            " [0.        ]\n",
            " [0.07660107]\n",
            " [0.13082007]\n",
            " [0.04825835]\n",
            " [0.08256733]\n",
            " [0.1805475 ]\n",
            " [0.13789344]\n",
            " [0.02357168]\n",
            " [0.21662714]\n",
            " [0.15015876]\n",
            " [0.17853887]\n",
            " [0.13336438]\n",
            " [0.16824132]\n",
            " [0.23604505]\n",
            " [0.14592007]\n",
            " [0.15664779]\n",
            " [0.30192664]\n",
            " [0.29104105]\n",
            " [0.3386404 ]\n",
            " [0.32145032]\n",
            " [0.24890977]\n",
            " [0.16775514]\n",
            " [0.17712739]\n",
            " [0.1326492 ]\n",
            " [0.28362918]\n",
            " [0.09373647]\n",
            " [0.28247628]\n",
            " [0.20939219]\n",
            " [0.1545886 ]\n",
            " [0.19882531]\n",
            " [0.13686384]\n",
            " [0.24443386]\n",
            " [0.11624914]\n",
            " [0.27769294]\n",
            " [0.20683764]\n",
            " [0.11774626]\n",
            " [0.2873852 ]\n",
            " [0.29764712]\n",
            " [0.24293493]\n",
            " [0.28286034]\n",
            " [0.3116067 ]\n",
            " [0.315959  ]\n",
            " [0.1293318 ]\n",
            " [0.16129056]\n",
            " [0.1914419 ]\n",
            " [0.2925579 ]\n",
            " [0.31191027]\n",
            " [0.21259326]\n",
            " [0.2950864 ]\n",
            " [0.23397465]\n",
            " [0.2750474 ]\n",
            " [0.1282604 ]\n",
            " [0.25986812]\n",
            " [0.278871  ]\n",
            " [0.19352904]\n",
            " [0.17504194]\n",
            " [0.1810841 ]\n",
            " [0.25577193]\n",
            " [0.17904736]\n",
            " [0.16995582]\n",
            " [0.26571688]\n",
            " [0.2912392 ]\n",
            " [0.33965942]\n",
            " [0.31318393]\n",
            " [0.11576799]\n",
            " [0.19030967]\n",
            " [0.19859634]\n",
            " [0.12204514]\n",
            " [0.23463503]\n",
            " [0.15290295]\n",
            " [0.32705256]\n",
            " [0.20016243]\n",
            " [0.28459948]\n",
            " [0.18482278]\n",
            " [0.30968052]\n",
            " [0.2634542 ]\n",
            " [0.272014  ]\n",
            " [0.1837568 ]\n",
            " [0.25506213]\n",
            " [0.26854303]\n",
            " [0.26973933]\n",
            " [0.34335247]\n",
            " [0.2723149 ]\n",
            " [0.37557498]\n",
            " [0.16435114]\n",
            " [0.1421119 ]\n",
            " [0.22213203]\n",
            " [0.24952386]\n",
            " [0.30149475]\n",
            " [0.14310989]\n",
            " [0.12445138]\n",
            " [0.2716476 ]\n",
            " [0.09748209]\n",
            " [0.24102055]\n",
            " [0.18744096]\n",
            " [0.29768324]\n",
            " [0.11075119]\n",
            " [0.13883086]\n",
            " [0.28342673]\n",
            " [0.19691995]\n",
            " [0.3880251 ]\n",
            " [0.13003813]\n",
            " [0.21874344]\n",
            " [0.15622991]\n",
            " [0.27796838]\n",
            " [0.16597758]\n",
            " [0.26794827]\n",
            " [0.08532828]\n",
            " [0.17085391]\n",
            " [0.19143558]\n",
            " [0.20188877]\n",
            " [0.25163963]\n",
            " [0.3245971 ]\n",
            " [0.3866736 ]\n",
            " [0.41689378]\n",
            " [0.46442538]\n",
            " [0.42211396]\n",
            " [0.5102283 ]\n",
            " [0.43226418]\n",
            " [0.42787626]\n",
            " [0.45678166]\n",
            " [0.3857082 ]\n",
            " [0.30152854]\n",
            " [0.42054877]\n",
            " [0.44563493]\n",
            " [0.30137154]\n",
            " [0.41999042]\n",
            " [0.3630553 ]\n",
            " [0.39737293]\n",
            " [0.42535514]\n",
            " [0.44476902]\n",
            " [0.40746817]\n",
            " [0.3823672 ]\n",
            " [0.39937362]\n",
            " [0.36508664]\n",
            " [0.4700964 ]\n",
            " [0.45613733]\n",
            " [0.4158143 ]\n",
            " [0.39751557]\n",
            " [0.4050932 ]\n",
            " [0.3915453 ]\n",
            " [0.39973786]\n",
            " [0.41687575]\n",
            " [0.43608078]\n",
            " [0.436684  ]\n",
            " [0.41250578]\n",
            " [0.5300424 ]\n",
            " [0.31698313]\n",
            " [0.43719402]\n",
            " [0.40211275]\n",
            " [0.4190303 ]\n",
            " [0.45594165]\n",
            " [0.4168897 ]\n",
            " [0.328846  ]\n",
            " [0.4248689 ]\n",
            " [0.424696  ]\n",
            " [0.3865134 ]\n",
            " [0.39912537]\n",
            " [0.4146376 ]\n",
            " [0.4573975 ]\n",
            " [0.3468445 ]\n",
            " [0.4295096 ]\n",
            " [0.45805478]\n",
            " [0.4299944 ]\n",
            " [0.3943554 ]\n",
            " [0.40726772]\n",
            " [0.4074735 ]\n",
            " [0.41056654]\n",
            " [0.43656206]\n",
            " [0.46254745]\n",
            " [0.363426  ]\n",
            " [0.4670583 ]\n",
            " [0.39509037]\n",
            " [0.4243882 ]\n",
            " [0.3852475 ]\n",
            " [0.37735125]\n",
            " [0.44141167]\n",
            " [0.4558915 ]\n",
            " [0.48421943]\n",
            " [0.4422695 ]\n",
            " [0.38070557]\n",
            " [0.32788965]\n",
            " [0.4191938 ]\n",
            " [0.44186267]\n",
            " [0.2865158 ]\n",
            " [0.42519403]\n",
            " [0.41814643]\n",
            " [0.36646208]\n",
            " [0.42094198]\n",
            " [0.41435027]\n",
            " [0.43105197]\n",
            " [0.42139047]\n",
            " [0.41281807]\n",
            " [0.45801318]\n",
            " [0.45245507]\n",
            " [0.3672578 ]\n",
            " [0.41379339]\n",
            " [0.4682342 ]\n",
            " [0.3902971 ]\n",
            " [0.36725348]\n",
            " [0.3692804 ]\n",
            " [0.43724453]\n",
            " [0.39741865]\n",
            " [0.44469175]\n",
            " [0.43889457]\n",
            " [0.4287767 ]\n",
            " [0.41016436]\n",
            " [0.46736294]\n",
            " [0.39502662]\n",
            " [0.43902358]\n",
            " [0.46305233]\n",
            " [0.17569606]\n",
            " [0.3985453 ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HSVVM7a0KRYk",
        "outputId": "63119350-fdb4-4cf1-bc25-39e6e37bede9"
      },
      "source": [
        "#Predicting Tylenol Data\n",
        "data = pd.read_csv('tylenol_topcare_samples.csv', index_col=0)\n",
        "data = pd.DataFrame(data)\n",
        "ternary_predictions = pd.DataFrame()\n",
        "\n",
        "ternary_predictions[\"label_name\"] =data[\"label_name\"]\n",
        "\n",
        "\n",
        "data.drop(['label_name'], axis=1, inplace=True)\n",
        "data.rename(columns={'Unnamed: 0': 'id'},inplace=True)\n",
        "\n",
        "X = data.values[:,0:]\n",
        "X = snv(X)\n",
        "X = pd.DataFrame(X)\n",
        "\n",
        "for i in range(227,1024,1):\n",
        "  X.insert(loc=i, column=i, value=0)\n",
        "\n",
        "ternary= X.values.reshape(X.shape[0],32,32,1).astype('float32')\n",
        "preds = model.predict(ternary)\n",
        "print (preds)\n",
        "\n",
        "se = pd.Series(preds.tolist())\n",
        "ternary_predictions.insert(loc=0, column='predictions', value=se.values)\n",
        "#Saving results\n",
        "ternary_predictions.to_csv('/content/Tylenol_Prediction_LeNet_2DCNN.csv')"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.09856251]\n",
            " [0.15627146]\n",
            " [0.14463487]\n",
            " ...\n",
            " [0.43873516]\n",
            " [0.45488247]\n",
            " [0.42457384]]\n"
          ]
        }
      ]
    }
  ]
}